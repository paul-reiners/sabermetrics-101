---
title: "Why did the Players League have so many R/G?"
author: "Paul Reiners"
date: "July 5, 2014"
output: html_document
---

The Players League (PL) was a professional league that lasted only one year, 1890. Something interesting happened in that league. Observe the runs per game of the PL, NL, and AA (American Association) in 1890 and a few surrounding years:

<img src="https://edxuploads.s3.amazonaws.com/14029396968096377.png" alt="runs per game league plot" />

R/G appears to be significantly greater in the PL than in the NL and AA (in 1890). What could be the potential cause for this difference? Was it better batting, worse pitching, factors such as park differences and rule differences, chance, or some combination of these?

In this article, we look at solely at batting. (In subsequent articles, we look at other possible causes.)

Consider players who played in the Players League (in 1890) and who also batted (in some other league) in the year before, 1889, and in the year after, 1891. To simplify our notation, let's call these players "PL players" even though they obviously did not play in the PL in years other than 1890. There are 93 such players. Not a large sample, but not a small sample, either. We will look at two questions regarding PL players:
<ul>
        <li>How did their R/G in 1890 (when they were in the PL) correspond to their R/G in 1889 and 1891 (when they were in other leagues)?</li>
	<li>How did their R/G in 1889 and 1891 correspond to non-PL players in 1889 and 1891?</li>
</ul>
The answer to the first question helps determine whether there was <strong>something different about the PL</strong>. The answer to the second question helps determine whether the PL batters were simply better than the non-PL batters.

To answer the first question, for each PL player, we do the following:
<ol>
	<li>Find the ratio for each hitter between their R/G in the PL and the average of their R/G in the preceding and succeeding years.</li>
	<li>Take the mean of all these ratios.</li>
</ol>
We get the following results:
<code>
1889 PL players R/G: 0.60
1890 PL players R/G: 0.71
1891 PL players R/G: 0.57
</code>
Let's summarize over the 1889 and 1891 seasons:

<code>1889/1891 PL players R/G: 0.60</code>

The mean of ratios turns out to be 1.24. So these players had higher R/G records in the PL than they had in other leagues. That is, <strong>any player who played in the PL, on average, had 1.24 times as many R/G as he had when he was in a league other than the PL</strong>.

For brevity, let's call this ratio the "PL advantage".

So we can conclude that there was something different about the PL such that players who played in the PL (in 1890) and in a major league other than the PL in 1889 and 1891 had a significantly higher R/G in the PL.

Now let's look at the second question.  We calculate the following statistics:

<code> 1889 PL players R/G: 0.66
1889 non-PL players R/G: 0.64
1891 PL players R/G: 0.66
1891 non-PL players R/G: 0.58
</code>

Let's summarize over the 1889 and 1891 seasons:

<code> PL players R/G: 0.66
Non-PL players R/G: 0.61</code>

So, the players who played in the PL outperformed the players who didn't play in the PL in R/G by a factor of 1.08 (when playing in non-PL leagues). This does not account for all of the 1.24 "PL advantage".

So we have shown that the PL players were better batters, but there was something else going on in the PL. What was it? To be continued...